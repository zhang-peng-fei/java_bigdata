<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <packaging>jar</packaging>
    <!--<parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>2.1.5.RELEASE</version>
        <relativePath/> &lt;!&ndash; lookup parent from repository &ndash;&gt;
    </parent>-->
    <groupId>com.zhangpengfei.bigData</groupId>
    <artifactId>java_bigData</artifactId>
    <version>0.1</version>
    <name>java_bigData</name>
    <description>java_bigData</description>
    <properties>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <!-- 版本 -->
        <java.version>1.8</java.version>
        <scala.binary.version>2.11</scala.binary.version>
        <flink.version>1.9.0</flink.version>
        <hadoop.version>2.10.1</hadoop.version>
        <storm.version>1.2.3</storm.version>
        <hbase.version>1.2.0</hbase.version>
        <kafka.version>0.10.2.2</kafka.version>
        <hive.version>2.3.5</hive.version>
        <!-- 作用域 -->
        <hadoop.scope>compile</hadoop.scope>
        <hive-exec.scope>compile</hive-exec.scope>
        <hbase.scope>compile</hbase.scope>
        <storm.scope>compile</storm.scope>
        <flink.scope>compile</flink.scope>
        <kafka.scope>compile</kafka.scope>
        <mysql-connector-java.scope>provided</mysql-connector-java.scope>
        <flink-shaded-jackson.scope>compile</flink-shaded-jackson.scope>
        <flink-connector-filesystem.scope>compile</flink-connector-filesystem.scope>
        <flink-connector-kafka.scope>compile</flink-connector-kafka.scope>
        <flink-connector-kafka-base.scope>compile</flink-connector-kafka-base.scope>
        <flink-shaded-hadoop-2-uber.scope>compile</flink-shaded-hadoop-2-uber.scope>
    </properties>
    <dependencies>
        <!--<dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-thymeleaf</artifactId>
            <scope>provided</scope>
        </dependency>-->

        <!--mysql数据库驱动-->
        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <version>5.1.47</version>
            <scope>${mysql-connector-java.scope}</scope>
        </dependency>

        <!--springboot启动依赖-->
        <!--<dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>provided</scope>
        </dependency>-->

        <!--
        Flink依赖开始
        flink-java,
        flink-table-common
        flink-table-api-java-bridge
        flink-streaming-java,
        flink-connector-kafka,
        flink-connector-kafka-base
        -->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-java</artifactId>
            <version>${flink.version}</version>
            <scope>compile</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-streaming-java_${scala.binary.version}</artifactId>
            <version>${flink.version}</version>
            <scope>compile</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-common</artifactId>
            <version>${flink.version}</version>
            <scope>${flink.scope}</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-api-java</artifactId>
            <version>${flink.version}</version>
            <scope>${flink.scope}</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-api-java-bridge_${scala.binary.version}</artifactId>
            <version>${flink.version}</version>
            <scope>${flink.scope}</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-connector-filesystem_${scala.binary.version}</artifactId>
            <version>${flink.version}</version>
            <scope>${flink-connector-filesystem.scope}</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-connector-kafka_${scala.binary.version}</artifactId>
            <version>${flink.version}</version>
            <scope>${flink-connector-kafka.scope}</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-connector-kafka-base_${scala.binary.version}</artifactId>
            <version>${flink.version}</version>
            <scope>${flink-connector-kafka-base.scope}</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-shaded-hadoop-2-uber</artifactId>
            <version>2.7.5-8.0</version>
            <scope>${flink-shaded-hadoop-2-uber.scope}</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-shaded-jackson</artifactId>
            <version>2.7.9-6.0</version>
            <scope>${flink-shaded-jackson.scope}</scope>
        </dependency>
        <!-- Flink 依赖结束-->

        <!-- Hadoop依赖开始
        hadoop-common
        hadoop-mapreduce-client-core
        -->
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-common</artifactId>
            <version>${hadoop.version}</version>
            <scope>${hadoop.scope}</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-mapreduce-client-core</artifactId>
            <version>${hadoop.version}</version>
            <scope>${hadoop.scope}</scope>
        </dependency>
        <!-- Hadoop 依赖结束-->

        <!-- Storm 依赖开始
        storm-core,
        storm-kafka,
        storm-kafka-client,
        storm-kafka-client-examples
         -->
        <dependency>
            <groupId>org.apache.storm</groupId>
            <artifactId>storm-core</artifactId>
            <version>2.0.0</version>
            <scope>${storm.scope}</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.storm</groupId>
            <artifactId>storm-kafka</artifactId>
            <version>${storm.version}</version>
            <scope>${storm.scope}</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.storm</groupId>
            <artifactId>storm-kafka-client</artifactId>
            <version>2.0.0</version>
            <scope>${storm.scope}</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.storm</groupId>
            <artifactId>storm-kafka-client-examples</artifactId>
            <version>2.0.0</version>
            <scope>${storm.scope}</scope>
        </dependency>
        <!-- Storm 依赖结束 -->

        <!-- Kafka 依赖开始
          kafka-clients,
           -->
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka-clients</artifactId>
            <version>${kafka.version}</version>
            <scope>${kafka.scope}</scope>
        </dependency>
        <!-- Kafka 依赖结束 -->

        <!-- Hbase 依赖开始
        hbase-client
        hbase-server
        -->
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-client</artifactId>
            <version>${hbase.version}</version>
            <scope>${hbase.scope}</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-server</artifactId>
            <version>${hbase.version}</version>
            <scope>${hbase.scope}</scope>
        </dependency>
        <!-- Hbase 依赖结束-->

        <!-- Hive依赖开始
        hive-exec
        hive-jdbc
        -->
        <dependency>
            <groupId>org.apache.hive</groupId>
            <artifactId>hive-exec</artifactId>
            <version>${hive.version}</version>
            <scope>${hive-exec.scope}</scope>
            <!-- 依赖冲突，排除冲突包-->
            <exclusions>
                <exclusion>
                    <groupId>org.apache.calcite</groupId>
                    <artifactId>calcite-core</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>org.apache.calcite</groupId>
                    <artifactId>calcite-avatica</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>org.apache.hive</groupId>
            <artifactId>hive-jdbc</artifactId>
            <version>${hive.version}</version>
        </dependency>
        <!-- Hive 依赖结束-->
        <!-- https://mvnrepository.com/artifact/com.codahale.metrics/metr5ics-core -->
        <dependency>
            <groupId>com.codahale.metrics</groupId>
            <artifactId>metrics-core</artifactId>
            <version>3.0.2</version>
            <scope>provided</scope>
        </dependency>

    </dependencies>


    <build>
        <plugins>
            <!-- Java Compiler -->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.1</version>
                <configuration>
                    <source>1.8</source>
                    <target>1.8</target>
                    <encoding>utf-8</encoding>
                </configuration>
            </plugin>
            <!--<plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
            </plugin>-->
        </plugins>
    </build>

</project>
